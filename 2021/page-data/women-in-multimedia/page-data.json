{
    "componentChunkName": "component---src-templates-article-js",
    "path": "/women-in-multimedia/",
    "result": {"data":{"site":{"siteMetadata":{"title":"ACM Multimedia Asia 2021"}},"markdownRemark":{"id":"a942854d-88d4-5313-a7a8-23b409284a54","excerpt":"The SIGMM EC has decided on a “25 in 25” strategy to strategically increase the participation of women in SIGMM and all its activities. This strategy aims at…","html":"<p>The SIGMM EC has decided on a <strong><a href=\"https://records.sigmm.org/2019/10/21/introducing-the-new-role-of-the-director-of-diversity-and-outreach/\" target=\"_blank\" rel=\"noreferrer\"><em>“25 in 25”</em></a></strong> strategy to strategically increase the participation of women in SIGMM and all its activities. This strategy aims at increasing the participation of women in all activities and committees of SIGMM to at least 25% by 2025.</p>\n<p>ACM Multimedia Asia 2021 is advocating for a better engagement and involvement of female researchers in all sorts of activities in Multimedia Asia and beyond. The Roundtable (scheduled on Day 2) invites six female panellists at different career stages to share their experiences at being a researcher and educator in multimedia. It will also be an event where participants, both women and men can meet up and exchange ideas.</p>\n<hr>\n<div class=\"keynote-text\">\n    <div class=\"keynote-img\">\n        <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 160px; border: solid 0.75px #ddd\">\n      <a class=\"gatsby-resp-image-link\" href=\"/2021/static/fb59b8d0cb498b97d7235c41c73436de/e4ec8/Si.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAQEAAwAAAAAAAAAAAAAAAAQDAQUG/8QAFgEBAQEAAAAAAAAAAAAAAAAAAwAC/9oADAMBAAIQAxAAAAGbXKwHjXNXn+RB7QGn/8QAGxAAAwADAQEAAAAAAAAAAAAAAQIDABESEyL/2gAIAQEAAQUCoy5xoFtFaq59UwRlQKdMT9Rc8f/EABgRAQEAAwAAAAAAAAAAAAAAAAEAEBJB/9oACAEDAQE/AR7buC//xAAZEQADAAMAAAAAAAAAAAAAAAAAAREQMUH/2gAIAQIBAT8BnCLD2f/EAB0QAAICAgMBAAAAAAAAAAAAAAERAAIQcTEyYYH/2gAIAQEABj8CVSXqAveBU1Wp35jLcB9n3H//xAAaEAEAAwEBAQAAAAAAAAAAAAABABEhQTFh/9oACAEBAAE/ISCvcNjOJvwzKmZlt9Mwqj4rpAb8FOxgvQTY/UDl7P/aAAwDAQACAAMAAAAQyA8A/8QAGBEAAwEBAAAAAAAAAAAAAAAAAAERQTH/2gAIAQMBAT8QqqY8DDlH/8QAGBEAAwEBAAAAAAAAAAAAAAAAAAERMUH/2gAIAQIBAT8QbJqCGnTY/8QAHRABAAIBBQEAAAAAAAAAAAAAAQARITFBUYGRcf/aAAgBAQABPxCkeoAUOvceA+HO53Duj5KLENrJZLxxAGUJBMnzaoyyDSRDrUVnKHsZLhUxtmV6ksz/2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Si Liu\" title=\"Si Liu\" src=\"/2021/static/fb59b8d0cb498b97d7235c41c73436de/e4ec8/Si.jpg\" srcset=\"/2021/static/fb59b8d0cb498b97d7235c41c73436de/e4ec8/Si.jpg 160w\" sizes=\"(max-width: 160px) 100vw, 160px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n    </div>\n    <!-- - **Title**: -->\n    <h3 class=\"name\">Si Liu (Panel Chair)</h3>\n    <!-- - **Date**: -->\n    <!-- - **Abstract**:  -->\n    <p class=\"subtitle\">Beihang University, China</p>\n    <p>\n        Dr. Si Liu is the leader of the CoLab and an associate professor in Beihang University. She was a visiting professor in Microsoft Research Asia. She used to work with Prof. Shuicheng Yan in National University of Singapore. She obtained Ph.D. degree from Institute of Automation, Chinese Academy of Sciences (CASIA), under the supervision of Prof. Hanqing Lu. She obtained Bachelor degree from Advanced Class of Beijing Institute of Technology (BIT).\n    </p>\n</div>\n<hr>\n<div class=\"keynote-text\">\n    <div class=\"keynote-img\">\n        <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 160px; border: solid 0.75px #ddd\">\n      <a class=\"gatsby-resp-image-link\" href=\"/2021/static/4be7d91995ad834b77e3082fab9967f0/e4ec8/Lina.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAQADAQAAAAAAAAAAAAAAAAQBAgUG/8QAFgEBAQEAAAAAAAAAAAAAAAAAAgEA/9oADAMBAAIQAxAAAAG6anUqxgj5W4u54U//xAAZEAADAQEBAAAAAAAAAAAAAAABAgMRABD/2gAIAQEAAQUCuWEgGn5VlVQ4Vd3pkmtiTLe//8QAFhEAAwAAAAAAAAAAAAAAAAAAASAx/9oACAEDAQE/ARE//8QAFREBAQAAAAAAAAAAAAAAAAAAEEH/2gAIAQIBAT8BpT//xAAdEAABBAIDAAAAAAAAAAAAAAABAAIRIRAxAyJB/9oACAEBAAY/AutE0g4chcPQcQdnSl+lSE2m4//EABwQAQACAwADAAAAAAAAAAAAAAEAESExURBBYf/aAAgBAQABPyF1e0W5Mj2L3rvgwuTCEMCdpAC0J0iIrLtjo/II0z//2gAMAwEAAgADAAAAECsIf//EABcRAQEBAQAAAAAAAAAAAAAAAAEQETH/2gAIAQMBAT8QBpYcn//EABcRAQEBAQAAAAAAAAAAAAAAAAEQETH/2gAIAQIBAT8QVwEeJ//EAB4QAQADAAICAwAAAAAAAAAAAAEAESFRYTFxgZGx/9oACAEBAAE/EM0xOJdfoY3UAutNI9XEpqXgCU6rz67j3ZLQBdPiH2rwljFH6iWscHa/LAgQOmp//9k='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Lina Yao\" title=\"Lina Yao\" src=\"/2021/static/4be7d91995ad834b77e3082fab9967f0/e4ec8/Lina.jpg\" srcset=\"/2021/static/4be7d91995ad834b77e3082fab9967f0/e4ec8/Lina.jpg 160w\" sizes=\"(max-width: 160px) 100vw, 160px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n    </div>\n    <!-- - **Title**: -->\n    <h3 class=\"name\">Lina Yao</h3>\n    <!-- - **Date**: -->\n    <!-- - **Abstract**:  -->\n    <p class=\"subtitle\">University of New South Wales, Australia</p>\n    <p>\n        Lina Yao is an Associate Professor at School of Computer Science and Engineering at the University of New South Wales (UNSW), Australia. Her research interest lies in machine learning, and its applications in recommender systems, activity modeling and prediction, the Internet of Things, and Brain-Computer Interface. She is serving as the Associate Editor for ACM Transactions on Sensor Networks (ACM TOSN) and Knowledge-based Systems (KNOSYS).\n    </p>\n</div>\n<hr>\n<div class=\"keynote-text\">\n    <div class=\"keynote-img\">\n        <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 160px; border: solid 0.75px #ddd\">\n      <a class=\"gatsby-resp-image-link\" href=\"/2021/static/71443830fe8fad2a0f7cd7461c6a06cf/e4ec8/lianli.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAMEAf/EABYBAQEBAAAAAAAAAAAAAAAAAAEAAv/aAAwDAQACEAMQAAABrnpwdQSGQ2BX/8QAHBAAAgIDAQEAAAAAAAAAAAAAAQIDBAAREiEz/9oACAEBAAEFApSQpQwgZO/GWW0F9FbTG194ief/xAAVEQEBAAAAAAAAAAAAAAAAAAABIP/aAAgBAwEBPwEj/8QAFhEBAQEAAAAAAAAAAAAAAAAAARAx/9oACAECAQE/AWGz/8QAGxAAAgMBAQEAAAAAAAAAAAAAAQIAETEhEBL/2gAIAQEABj8CpdPIG+ie98WtuJeX4zMoJuNNn//EABoQAQADAQEBAAAAAAAAAAAAAAEAESExEEH/2gAIAQEAAT8hCdek2VxV5vgbNEoRhdLJEWHGZUDSnI8/hhL/AF2f/9oADAMBAAIAAwAAABAEAAD/xAAXEQEBAQEAAAAAAAAAAAAAAAABEBEx/9oACAEDAQE/EAYseT//xAAYEQEAAwEAAAAAAAAAAAAAAAABABARMf/aAAgBAgEBPxBOhY9n/8QAHhABAAMAAQUBAAAAAAAAAAAAAQARITFBUWFxkdH/2gAIAQEAAT8QCCy+HqvwY+UEuNOy+0GPuGUDgdK/TI+CFeioQS16D4hJHa0cPHyItVUB6FGQQBhkHjCf/9k='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Lianli Gao\" title=\"Lianli Gao\" src=\"/2021/static/71443830fe8fad2a0f7cd7461c6a06cf/e4ec8/lianli.jpg\" srcset=\"/2021/static/71443830fe8fad2a0f7cd7461c6a06cf/e4ec8/lianli.jpg 160w\" sizes=\"(max-width: 160px) 100vw, 160px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n    </div>\n    <!-- - **Title**: -->\n    <h3 class=\"name\">Lianli Gao</h3>\n    <!-- - **Date**: -->\n    <!-- - **Abstract**:  -->\n    <p class=\"subtitle\">University of Electronic Science and Technology of China, China</p>\n    <p>\n        Dr. Lianli Gao is a Professor at School of Computer Science and Engineering, UESTC. She is a member of the CFM Lab. She obtained her PhD degree in Information Technology from The University of Queensland (UQ), Australia, under the supervision of  Prof. Jane Hunter and Prof. Michael Bruenig. She received her BS degree in Computer Science from UESTC, in 2009. \n        Her research ranges from Semantic Web, Machine Learning, Deep Learning, Computer Vision (Images and Videos), NLP, Knowledge Reasoning, Knowledge and the related practical applications etc. Specifically, she is mainly focusing on integrating Natural Language for Visual Content Understanding. \n    </p>\n</div>\n<hr>\n<div class=\"keynote-text\">\n    <div class=\"keynote-img\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 160px; border: solid 0.75px #ddd\">\n      <a class=\"gatsby-resp-image-link\" href=\"/2021/static/cf4b127742f9fdf60adf4ec27f13df56/e4ec8/Mahsa.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAIEBQED/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAasb0DOdWWvcjMFf/8QAHBAAAgICAwAAAAAAAAAAAAAAAQMAAgQhEBEx/9oACAEBAAEFAqqNgxZrwnaLjuH3GJDXaE//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAcEAAABwEBAAAAAAAAAAAAAAAAAQIQESExQWH/2gAIAQEABj8CL0a23IVbRwwpv//EAB0QAAMAAQUBAAAAAAAAAAAAAAABESEQMUFRgWH/2gAIAQEAAT8hcS9Edqux4ZMlCQVV4JqbCwv0RkFzp//aAAwDAQACAAMAAAAQSAD8/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxAf/8QAFhEBAQEAAAAAAAAAAAAAAAAAEAEx/9oACAECAQE/EC6f/8QAHBABAAIDAAMAAAAAAAAAAAAAAQARITFREEGh/9oACAEBAAE/ENiqdsBBQT0QYGHJIunJeSOdWteldnwqKZhTtQpFrKKfH//Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Mahsa Baktashmotlagh\" title=\"Mahsa Baktashmotlagh\" src=\"/2021/static/cf4b127742f9fdf60adf4ec27f13df56/e4ec8/Mahsa.jpg\" srcset=\"/2021/static/cf4b127742f9fdf60adf4ec27f13df56/e4ec8/Mahsa.jpg 160w\" sizes=\"(max-width: 160px) 100vw, 160px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n    </div>\n    <!-- - **Title**: -->\n    <h3 class=\"name\">Mahsa Baktashmotlagh</h3>\n    <!-- - **Date**: -->\n    <!-- - **Abstract**:  -->\n    <p class=\"subtitle\">The University of Queensland, Australia</p>\n    <p>\n        Mahsa Baktashmotlagh is currently a Lecturer at UQ with a research focus, developing machine learning and datamining techniques applied in: Visual data analysis (Visual domain adaptation, video classification, and animal’s foragingbehavioural analysis), Road traffic networks (Mining large scale road traffic networks and building a road loadbalancing tool to predict congestion on any road in the city) , Biomedical data (Prediction of neonatal sepsis), and Finance (Hedging foreign exchange trading risks).\n    </p>\n</div>\n<hr>\n<div class=\"keynote-text\">\n    <div class=\"keynote-img\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 160px; border: solid 0.75px #ddd\">\n      <a class=\"gatsby-resp-image-link\" href=\"/2021/static/43a6d603847f21399076a6fb4ab3fffd/e4ec8/Ran.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAMEBQIG/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQL/2gAMAwEAAhADEAAAAbWNbkK2EBjykwVwKP/EABsQAAMAAwEBAAAAAAAAAAAAAAECAwQRIgAS/9oACAEBAAEFAs08qvMW+5Vpu9SqzwzvGc+sSQKOo//EABURAQEAAAAAAAAAAAAAAAAAAAEg/9oACAEDAQE/ASP/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAaEAEBAQEAAwAAAAAAAAAAAAABAAIRMVGR/9oACAEBAAY/AgtNnXsgfEvyxdsXDSX/xAAbEAEAAwEBAQEAAAAAAAAAAAABABEhMXFBUf/aAAgBAQABPyHqM6zQXfyKt3SFLqYFhXqeSyMonYoL0uVh34M//9oADAMBAAIAAwAAABDg4H3/xAAYEQEBAAMAAAAAAAAAAAAAAAAAASExUf/aAAgBAwEBPxCMLt1X/8QAFxEBAQEBAAAAAAAAAAAAAAAAAQAQMf/aAAgBAgEBPxBcekX/xAAcEAEAAgMAAwAAAAAAAAAAAAABABEhMUFRcYH/2gAIAQEAAT8QcKwNB15KqKC8HcQywq8vZX+tVExeiPb3wsTZMlfxYvjAbiKnKt7iH7RW2E//2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Ran Yi\" title=\"Ran Yi\" src=\"/2021/static/43a6d603847f21399076a6fb4ab3fffd/e4ec8/Ran.jpg\" srcset=\"/2021/static/43a6d603847f21399076a6fb4ab3fffd/e4ec8/Ran.jpg 160w\" sizes=\"(max-width: 160px) 100vw, 160px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n    </div>\n    <!-- - **Title**: -->\n    <h3 class=\"name\">Ran Yi</h3>\n    <!-- - **Date**: -->\n    <!-- - **Abstract**:  -->\n    <p class=\"subtitle\">Shanghai Jiao Tong University, China</p>\n    <p>\n        Ran Yi is an Assistant Professor at Shanghai Jiao Tong University (SJTU). She is a member of SJTU Digital Media and Computer Vision Laboratory. She received her Ph.D. degree from CSCG Group, Tsinghua University in 2021, advised by Prof. Yong-Jin Liu. She also closely collaborates with Prof. Yu-Kun Lai, Prof. Paul L. Rosin and Prof. Ying He.\n    </p>\n</div>\n<hr>\n<div class=\"keynote-text\">\n    <div class=\"keynote-img\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 160px; border: solid 0.75px #ddd\">\n      <a class=\"gatsby-resp-image-link\" href=\"/2021/static/1959292d17b863ba8cfa2863d414cb19/e4ec8/laikuan.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAQFA//EABUBAQEAAAAAAAAAAAAAAAAAAAEC/9oADAMBAAIQAxAAAAHVzqIprfTqnJ4g0BP/xAAeEAACAgICAwAAAAAAAAAAAAABAgADBBEFEhMjMf/aAAgBAQABBQLIsKIbGpn2Zh6y9/Xj78HIE99BpWxVf//EABcRAQADAAAAAAAAAAAAAAAAABABMUH/2gAIAQMBAT8BijD/xAAVEQEBAAAAAAAAAAAAAAAAAAABIP/aAAgBAgEBPwFj/8QAHhAAAQQCAwEAAAAAAAAAAAAAAQACEUEhUQMQEjH/2gAIAQEABj8Cx9OEHey4WD1xuoFRtMnSAoLNBQDAX//EABoQAQEBAQEBAQAAAAAAAAAAAAERADEhQVH/2gAIAQEAAT8hBDjw/mYP6kvmEAnHWP0XDdD87tq4q3woZkjwIasQPDf/2gAMAwEAAgADAAAAEM8Ivv/EABcRAQEBAQAAAAAAAAAAAAAAAAEQETH/2gAIAQMBAT8QArYdT//EABcRAQEBAQAAAAAAAAAAAAAAAAEQEUH/2gAIAQIBAT8QTs6T/8QAHxABAAIDAAEFAAAAAAAAAAAAAQARITFBUWFxgaHx/9oACAEBAAE/EAFDq9Fr8BG7tMEV08MUqwsfJM+OMvZ+y720KGuwgiEijft9RYOjwW7Y6Ll7MZM3NE8EoJ//2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Lai Kuan Wong\" title=\"Lai Kuan Wong\" src=\"/2021/static/1959292d17b863ba8cfa2863d414cb19/e4ec8/laikuan.jpg\" srcset=\"/2021/static/1959292d17b863ba8cfa2863d414cb19/e4ec8/laikuan.jpg 160w\" sizes=\"(max-width: 160px) 100vw, 160px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n    </div>\n    <!-- - **Title**: -->\n    <h3 class=\"name\">Lai-Kuan Wong</h3>\n    <!-- - **Date**: -->\n    <!-- - **Abstract**:  -->\n    <p class=\"subtitle\">Multimedia University, Malaysia</p>\n    <p>\n        Lai-Kuan Wong is currently an Associate Professor and Chair of the Centre for Visual Computing (CVC) at Multimedia University, Malaysia, where she also served as the Deputy Dean of Research and Innovation for Faculty of Computing and Informatics in 2018-2021. She received her Ph.D. in Computer Science from National University of Singapore. Her research interests include computational photography and computational aesthetics, 3D scene analysis and understanding, and medical imaging. Lai-Kuan has co-chaired several workshops (Workshops at ACM Multimedia 2020, ACCV 2018, ACPR 2015), and regularly serves as the technical program committee for reputable conferences (CVPR, AAAI, WACV, ACM Multimedia, MMM) and as a reviewer for several IEEE Transactions. She also serves as the organizing committee for several conferences including the upcoming IEEE ICME 2022, IEEE ISPACS 2022, and IEEE ICIP 2023. She is the Technical Committee for APSIPA SPS TC since 2018.\n    </p>\n</div>\n<style>\n    .keynote-text {\n        text-align: left;\n    }\n    .keynote-img {\n        float: none;\n        margin-right: 1.8rem;\n        margin-bottom: 1rem;\n        width: 160px;\n    }\n    .note {\n        font-size: 14px;\n        color: grey;\n    }\n    .name {\n        margin-bottom: 0.5rem !important;\n    }\n\n    @media (min-width: 768px) {\n        .keynote-text {\n            text-align: justify;\n        }\n        .keynote-img {\n            float: left;\n        }\n    }\n</style>","frontmatter":{"title":"Women in Multimedia Roundtable","datePublished":"2021-11-25","dateModified":"2021-11-25","dateModifiedFormatted":"25 November, 2021","description":"ACM Multimedia Asia 2021 is advocating for a better engagement and involvement of female researchers in all sorts of activities in Multimedia Asia and beyond."}}},"pageContext":{"id":"a942854d-88d4-5313-a7a8-23b409284a54","previousPostId":"00e753e9-db86-50a8-add6-b23da35f97fd","nextPostId":"e51e7b4d-47b0-5796-b094-0168e9013113"}},
    "staticQueryHashes": ["4054665497"]}